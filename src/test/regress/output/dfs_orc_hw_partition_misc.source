set enable_global_stats = true;
--
-- HDFS Partition table testing [3]
-- Exceptional scenarios;
--
drop schema if exists exception_scenarios;
NOTICE:  schema "exception_scenarios" does not exist, skipping
create schema exception_scenarios;
set search_path=exception_scenarios;
-- not allowed data type bool
create table t1 (c1 int, not_allowed_type boolean) tablespace hdfs_ts distribute by hash (c1) partition by values (not_allowed_type);
ERROR:  column "not_allowed_type" cannot be served as a value-partitioning column because of its datatype [boolean]
-- not allowed data type oid
create table t1 (c1 int, not_allowed_type oid) tablespace hdfs_ts distribute by hash (c1) partition by values (not_allowed_type);
ERROR:  column "not_allowed_type" cannot be served as a value-partitioning column because of its datatype [oid]
-- not allowed data type MONEY
create table t1 (c1 int, not_allowed_type money) tablespace hdfs_ts distribute by hash (c1) partition by values (not_allowed_type);
ERROR:  column "not_allowed_type" cannot be served as a value-partitioning column because of its datatype [money]
-- not allowed data type REAL
create table t1 (c1 int, not_allowed_type real) tablespace hdfs_ts distribute by hash (c1) partition by values (not_allowed_type);
ERROR:  column "not_allowed_type" cannot be served as a value-partitioning column because of its datatype [real]
-- not allowed data type double
create table t1 (c1 int, not_allowed_type double precision) tablespace hdfs_ts distribute by hash (c1) partition by values (not_allowed_type);
ERROR:  column "not_allowed_type" cannot be served as a value-partitioning column because of its datatype [double precision]
-- not allowed data type clob
create table t1 (c1 int, not_allowed_type clob) tablespace hdfs_ts distribute by hash (c1) partition by values (not_allowed_type);
-- not allowed data type bytea --- failed at ORC column type check rather than partition column check
create table t1 (c1 int, not_allowed_type bytea) tablespace hdfs_ts distribute by hash (c1) partition by values (not_allowed_type);
ERROR:  type "bytea" is not supported in DFS ORC format column store
-- not allowed data type NAME --- failed at ORC column type check rather than partition column check
create table t1 (c1 int, not_allowed_type NAME) tablespace hdfs_ts distribute by hash (c1) partition by values (not_allowed_type);
ERROR:  type "name" is not supported in DFS ORC format column store
-- not allowed data type int2vector --- failed at ORC column type check rather than partition column check
create table t1 (c1 int, not_allowed_type int2vector) tablespace hdfs_ts distribute by hash (c1) partition by values (not_allowed_type);
ERROR:  type "int2vector" is not supported in DFS ORC format column store
--
-- If partitioned table contains more than one column not supported by partition key, report the fist invalid column
--
create table t1 (c1 int, c2 int2vector, c3 clob, c4 real) tablespace hdfs_ts distribute by hash (c1) partition by values (c2,c3,c4);
ERROR:  type "int2vector" is not supported in DFS ORC format column store
--
-- If partitioned table contains more than 4 columns, should fail
--
create table t1 (c1 int, c2 int, c3 int, c4 int, c5 int, c6 int) tablespace hdfs_ts distribute by hash (c1) partition by values (c2,c3,c4,c5,c6);
ERROR:  Num of partition keys in value-partitioned table exceeds max allowed num:4
--
-- If partitioned table contains special characters
--
create table t1(c1 int, c2 text) tablespace hdfs_ts distribute by hash (c1) partition by values (c2);
ERROR:  relation "t1" already exists
-- pass
insert into t1 values (1, repeat('C', 508));
ERROR:  Before encoding, the length of data as partition directory name must be less than dfs_partition_directory_length(512)/3.
-- pass
insert into t1 values (1, repeat('C', 510));
ERROR:  Before encoding, the length of data as partition directory name must be less than dfs_partition_directory_length(512)/3.
-- fail as # needs UTI encoding when forming directory
insert into t1 values (1, repeat('#', 509));
ERROR:  Before encoding, the length of data as partition directory name must be less than dfs_partition_directory_length(512)/3.
delete from t1;
drop table if exists p_hdfs_dec1000_tab_001;
NOTICE:  table "p_hdfs_dec1000_tab_001" does not exist, skipping
create table p_hdfs_dec1000_tab_001(c1 int, c2 decimal(1000,1), c3 int) tablespace hdfs_ts partition by values(c2);
set cstore_insert_mode=main;
insert into p_hdfs_dec1000_tab_001 values(1, 11.1, 3);
insert into p_hdfs_dec1000_tab_001 values(1, 1111.1, 3);
set cstore_insert_mode=delta;
insert into p_hdfs_dec1000_tab_001 values(1, 999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999.9, 3);
set cstore_insert_mode=main;
vacuum deltamerge p_hdfs_dec1000_tab_001;
ERROR:  The length of the partition directory exceeds the current value(512) of the option "dfs_partition_directory_length", change the option to the greater value.
DETAIL:  the path name is "c2=999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999.9/".
drop table p_hdfs_dec1000_tab_001;
drop table if exists hdfs_predpushdown_table_001;
NOTICE:  table "hdfs_predpushdown_table_001" does not exist, skipping
create table hdfs_predpushdown_table_014_02 (
	c1 int,
	c_char char(30),
	c_char2 CHARACTER(100),
	c_char3 NCHAR(100),
	c4 int)
with(compression='no',orientation=orc,version=0.12) tablespace hdfs_ts
 partition by values(c_char,c_char2,c_char3);
set cstore_insert_mode=delta;
insert into hdfs_predpushdown_table_014_02 values (1, repeat('C', 30), repeat('C', 100), repeat('C', 100), 3);
set cstore_insert_mode=main;
vacuum deltamerge hdfs_predpushdown_table_014_02;
drop table hdfs_predpushdown_table_014_02;
-- testing special characters
insert into t1 values (0, ' ');
insert into t1 values (1, '~');
insert into t1 values (2, '`');
insert into t1 values (3, '!');
insert into t1 values (4, '#');
insert into t1 values (5, '%');
insert into t1 values (6, '^');
insert into t1 values (7, '&');
insert into t1 values (8, '*');
insert into t1 values (9, '(');
insert into t1 values (10, ')');
insert into t1 values (11, '_');
insert into t1 values (12, '-');
insert into t1 values (13, '+');
insert into t1 values (14, '=');
insert into t1 values (15, '{');
insert into t1 values (16, '}');
insert into t1 values (17, '[');
insert into t1 values (18, ']');
insert into t1 values (19, '|');
insert into t1 values (20, '\\');
insert into t1 values (21, ':');
insert into t1 values (22, ';');
insert into t1 values (23, '"');
insert into t1 values (24, '''');
insert into t1 values (25, '<');
insert into t1 values (26, '>');
insert into t1 values (27, ',');
insert into t1 values (28, '.');
insert into t1 values (29, '?');
insert into t1 values (30, '/');
select * from t1 order by 1;
 c1 | not_allowed_type 
----+------------------
  0 |  
  1 | ~
  2 | `
  3 | !
  4 | #
  5 | %
  6 | ^
  7 | &
  8 | *
  9 | (
 10 | )
 11 | _
 12 | -
 13 | +
 14 | =
 15 | {
 16 | }
 17 | [
 18 | ]
 19 | |
 20 | \\
 21 | :
 22 | ;
 23 | "
 24 | '
 25 | <
 26 | >
 27 | ,
 28 | .
 29 | ?
 30 | /
(31 rows)

drop table t1;
drop schema exception_scenarios cascade;
